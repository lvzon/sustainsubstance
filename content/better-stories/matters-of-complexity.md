Title: Entwined: Matters of Complexity
Authors: Levien van Zon
Date: 2024-06-21
Tags: complexity
Slug: entwined

Reading time: ca. 15-25 minutes.     
Too long? Read the [8 minute summary]({filename}/pages/summary-entwined.md) instead!

*This article has been published on [https://lvzon.substack.com](https://lvzon.substack.com/p/entwined), and is also available as [PDF]({static}/offline/sustainsubstance-20240618-matters-of-complexity.pdf) or ebook ([EPUB]({static}/offline/sustainsubstance-20240618-matters-of-complexity.epub) and [Kindle]({static}/offline/sustainsubstance-20240618-matters-of-complexity.azw3)) for offline reading. You can  listen to a narrated version on [Substack](https://lvzon.substack.com/p/entwined), [Youtube](https://youtu.be/UtJgkYCqjgc), [Spotify](https://open.spotify.com/episode/0urK3kecS0DIGs5XZz5Zfy?si=F9l0LvNJTY2rYqyUzPtOXA) or [Apple Podcasts](https://podcasts.apple.com/us/podcast/entwined/id1745586120?i=1000659742373).*

This article and the next will be a little more technical, we will look at so-called *complex systems*. 
I will refer to complexity in future articles, and here I will explain what it is, how we can talk about it and what this all means for scientific understanding, predictability and the possibilities of control.

<div style="text-align: center; margin-left: auto; margin-right: auto;">
<img src="{static}/images/red-thread.jpg" style="width: 100%; height: auto; border: 0px;"/>
</div>


**By Levien van Zon**

We understand our world through stories.
As I wrote in my [previous article](https://sustainsubstance.org/beyond-optimists-and-pessimists.html), how we see and how we talk about the world matters a lot for the way we understand our surroundings.
This in turn determines which problems we see and how we choose to deal with them.
Stories are much more than just "fiction". 
They are internal models of the world that we share with others through the magical medium of language. 
Stories constitute knowledge, both for us as individuals and as a species.

Many of our day-to-day stories about the world are sloppy and inconsistent.
Therefore much of our modern knowledge derives from science. 
Science aims to tell stories that are more formal and more precise, and that can be examined for their accuracy.
When we're looking for better stories, science is not a bad place to start.

### Welcome to the machine

Since about the 17th century, how we see the world has increasingly been determined by science and technology. 
Especially the concept of "the machine" has been very important in shaping our thinking as well as our "doing".
Many early scientists imagined the world as being similar to a giant machine or clockwork. 
They believed that this [clockwork universe](https://en.wikipedia.org/wiki/Clockwork_universe) could be fully understood and predicted, once the mechanical laws that govern it had been uncovered.
Enlightenment thinkers often talked about life and human society in terms of machines as well.
For instance, René Descartes famously argued that animals were basically just automatons, biological machines incapable of conscious experience because they lacked a human soul. 

The Industrial Revolution in the 18th and 19th centuries saw the development, study and optimisation of actual human-built machines for an increasing range of tasks. 
This yielded further insights into all kinds of mechanical laws, but also into the role of energy, including the behaviour of heat, electricity, magnetism and light.
Increasingly, nature was seen as something that could and *should* be controlled and improved for the benefit of humans.
The forests of Europe were turned into artificial monocultures, optimised for the greatest yield of wood.
In the 20th century, the efficiency of factories was maximised according to the "rational" principles of ["scientific management"](https://en.wikipedia.org/wiki/Scientific_management) devised by Frederick Taylor and others.[^taylorism] 
Buildings and cities were reimagined as "machines for living and working" by the architects and designers of [CIAM](https://en.wikipedia.org/wiki/Congr%C3%A8s_Internationaux_d%27Architecture_Moderne), the International Congresses of Modern Architecture.
Much of agriculture was also modelled after the ideal of the factory, which was based on mechanisation, standardisation, scale and control. The aim was to replace the seeming chaos of nature by the efficiency of the factory, in order to increase the production and predictability of food, vegetable oil and fibre. This also resulted in driving down their cost.

In many ways these collective attempts to understand and improve the world through science and technology were an astounding success.
We understand almost unimaginably more about the universe than we did a few centuries ago, and in many countries the quality and span of human life have greatly increased since then.
But these successes did come at a cost. 
Some of these costs took (and still take) the form of human and non-human suffering, for instance in the former colonies and in industrial production chains, including those of agriculture.
Moreover, while over the past centuries we collectively managed to reduce some problems, we've created many new ones, or made existing problems worse.
One unintended consequence of mechanisation turned out to be climate change. 
Other examples of the darker sides of "progress" include biodiversity loss, soil degradation, water shortages, microbial resistance and a pandemic of chronic metabolic diseases (such as diabetes). Also some aspects of social and economic inequality have been created or made worse by technological progress.

If we want to solve and prevent such problems, it is important to figure out why they occur in the first place.
Many "modern" problems are unintended and unexpected side effects of our attempts to improve human wellbeing.
Proponents of technological solutions sometimes argue that these are simply a temporary price that we need to pay for progress.
Further improvements in knowledge and technology will allow us to solve these problems and prevent new ones. 
Is this a realistic expectation, or is it just wishful thinking?

To understand both the success and the limitations of science and technology, it helps to comprehend a little better how science works, and why it is so effective in answering some questions while it has trouble with others.
As we shall see, many problems actually have to do with our tendency to use human-built machines as a metaphor for how the world and everything in it works.
Machines are built to be optimised and controlled.
But it turns out that most of our world is very unlike a machine.

### Stories, science and the iron rule

We all use stories to explain and predict what happens in our surroundings. 
To find out how accurate our explanations and predictions are, our brains constantly compare our expectations with our actual observations and experiences.[^bayesianbrain]
In principle, the way in which science works is not much different. 
Scientific theories are basically explanatory and predictive stories, and we constantly compare them with observations to see if they are accurate.
However, there is at least one important thing that sets scientific explanations apart from other types of stories.
Regular stories tend to act as a source of certainty, they provide a framework on which we build our beliefs. 
If we encounter observations that are inconsistent with our explanatory stories, we tend to hold on to our stories and we often ignore or explain away the inconsistent observations.
This also happens in science, of course, simply because scientists are humans. 
But science has the underlying, collective rule that, at least in principle, observations are *always* more important than the story used to explain them. 
Philosopher [Michael Strevens](https://www.strevens.org/scientia/) has called this "the iron rule of science".
And this rule is considered sufficiently valuable that (eventually) it tends to win out against human nature:
If the explanation doesn't match the observation, the story isn't good enough and should be modified.

Observations in science often involve active and repeatable manipulations of the world, in the form of experiments.
The language of scientific stories is usually a "natural" human language such as English. 
But when possible, the more precise "non-natural" languages of mathematics and logic are used, as these are less ambiguous and have greater predictive power. 
Whatever the form, the purpose is the same: to describe a part of the world, in an attempt to understand how it works in the most precise way possible. 
This has been especially successful for understanding the non-living physical universe. 

The living world, which includes human societies, has been harder to describe and comprehend. 
Later we will explore some of the reasons for this. 
For now let's just state that the living world is more complex than the non-living world. 
And this has proven somewhat of a challenge for the tools that science has traditionally used.

The "classical" way to do science is often called *reductionism*. 
The reductionist method basically works by taking complicated things apart.
The parts are then manipulated and studied in isolation. 
In this way, a description of more complicated assemblages is built up from descriptions of its parts.

This works well, as long as the behaviour of an assemblage is mostly determined by the properties of the parts (or by statistical regularities in the interactions of parts).
For instance, finding out the properties of atoms and simple molecules greatly increased our understanding of how more complicated molecules work. 
It also explained much about the properties of gases, fluids and solids, which are formed from large numbers of interacting atoms or molecules.

Studying parts in a controlled environment allows us to break up the study of complicated things into smaller, more manageable projects.
These simpler studies can also be more easily repeated and checked by others. 
This method is very powerful, and has been extremely successful.
However, it encounters difficulties when there are *many* interactions between elements. 
When such interactions are significant and are not easy to "aggregate" into neat statistics, 
it becomes hard to explain a system's behaviour by just studying the interacting parts. 
This is where complexity science can help us, because it is in many respects a "science of interactions". 
It is actually not so much a science in itself, but more an add-on to the various sciences. 
It is a toolkit for thinking and talking about complex systems.

### Interacting elements

So what is a complex system? A *system* is a collection of elements.
These elements need to be interconnected in ways that produce some collective behaviour. 
If a system is *complex*, it usually means that the system has many parts. 
Also, interactions between these parts are important for collective behaviour. 
The word "complex" comes from Latin, and basically means "entwined". 

In a complex system, the parts are hard to separate. 
An example is your body: if you start taking it apart into separate organs or cells, at some point it will stop working well. 
The same applies to most living systems, which is why they are hard to study using the reductionist method. 
You cannot really take them apart without changing the way they work. 
And performing controlled experiments on the interacting parts of a fully functional system isn't easy. 
Reliably repeating such experiments is even harder.

<div style="text-align: center; margin-left: auto; margin-right: auto;">
<img src="{static}/images/complexity-tangle-cropped-small.jpg" style="border: 0px;"/>
</div>

We should point out that complexity isn't a binary category. 
It's not that something is either simple or complex. 
Complexity is a continuum, some things are more complex than others. 
More complexity can result from more parts or interactions, or because interactions are stronger or more varied. 

Here it is useful to make a distinction between two kinds of complex systems: *complex physical systems* (CPS) and *complex adaptive systems* (CAS). 
Complex physical systems have many parts that interact, but the parts themselves *don't change much over time*. 
A relatively simple example would be a pile of sand grains. 
A more complex example is the weather.

In a complex *adaptive* system on the other hand, the *parts aren't static*, they can change over time. 
If parts can change, and if they don't all change in the same way, 
individual elements may become different from each other in their properties. 
Complex adaptive systems therefore tend to have *diversity* in their elements. 
And as the name already implies, complex adaptive systems can *adapt* to changing conditions. 
All living systems are complex adaptive systems. 
Examples include biological cells, tissues and organs, organisms, ecosystems and human societies and economies.

### More than the sum of its parts

In both types of complex systems, interactions between the parts can lead to interesting things. 
One of these is *emergence*. This basically means that an assemblage of parts has properties that its parts do not have. 
Think for instance of water, which (in its liquid form) can flow and is wet. 
Water is formed from interacting molecules, but a single water molecule cannot be said to be "wet". 
And even though all water molecules are alike, the [many properties of water](https://en.wikipedia.org/wiki/Properties_of_water) cannot easily be predicted from knowing the properties of a water molecule.

Water molecules are the building blocks of liquid water, they can also form ice or water vapour.
In general, interacting molecules give rise to gases, fluids or solids. 
We can think of these "states of matter" as new *levels of organisation*, which *emerge* from the interactions between molecules. 
A fluid or solid is a "thing" in itself, which has its own properties and follows its own peculiar rules. 
Water and ice are clearly very different, even though they are both made up of identical water molecules. 
The different *emergent properties* of water, ice and water vapour arise because the same molecules interact in different ways.

Emergence is sometimes presented as exotic, hard to study and almost mystical. 
Yet we are completely surrounded by it, and it determines our daily experience. 
We cannot see molecules interact, so of course we are not used to thinking of the "things" that surround us as emerging from interacting molecules. 
And this is precisely the point: even if we don't know anything about molecules, 
we can interact with things that are made up of molecules, 
because such emergent levels of organisation have their own emergent properties of "thingness". 
You can simply sit on a chair without being aware of the molecules of iron, nickel and nitrogen that interact to form crystal microstructures that (hopefully) keep the steel frame of the chair together. 

Even if we *are* interested in the finer details of things, a medical specialist can study and treat heart problems without knowing all of the processes going on in the human body, or all the molecular components that make up the human heart. 
And an economist can say something about the global market for office chairs without having to study the detailed neural patterns in the brains of all the people that are involved in producing, selling and buying such chairs.
Emergent properties allow us to know things without having to know all of the underlying details.

### Strict laws, shaky laws

In the 17th century, scientists like Isaac Newton believed that much of the universe was governed by a limited and unchanging set of "laws". 
These laws were presumed to be set by the Creator, and humans could "discover" them through careful experimentation and observation. 
Finding the laws of nature was like unveiling the mind of God.
Over the subsequent centuries, especially physicists proved to be very successful in finding such scientific laws. 
Notably at the subatomic level, many of the rules that govern quantum mechanics seem to be static, fundamental properties of the universe in some way.

One example is the little-known *Pauli exclusion principle*, a [simple rule](https://en.wikipedia.org/wiki/Pauli_exclusion_principle) that prescribes the structure of the periodic table of elements and many of the properties of matter in our universe. 
A rule like this has a huge effect on the structure of reality, yet is not entirely clear where it comes from.

Following the successes in physics and chemistry, scientists in other fields also started searching for scientific laws. 
However, the more complex the system that they were studying, the harder it was to find regularities, let alone true "natural laws". 
Rules and regularities in the more complex realms of biology, economics and the social sciences bear little resemblance to the "hard" predictive laws of physics. 
They are usually more trends than laws: they tend to depend on context, it is often possible to find exceptions and the rules can suddenly change.

It turns out that even in physics and chemistry, many of the "laws of nature" are not unchanging properties of the universe. 
Rather, they are emergent properties[^emergence] of interacting particles and forces, and they may also depend on context.
As long as the interacting parts (say, molecules) and their surroundings are constant over time, their collective behaviour is often well-defined.[^epa]
For instance, it is a well-known fact that water freezes at 0°C and boils at 100°C. But oddly this is almost never the case in the real world.
It is only true for pure water under a standard pressure of 1 atmosphere, and under fairly slow heating or cooling.
Any deviation from standard pressure (for instance with altitude) or anything that is dissolved into water (for instance salt) will shift the boiling and freezing points to higher or lower temperatures. 
But at least water molecules are all the same, so the effects of such external influences are more or less predictable.

However as I already mentioned, discovering the behavioural rules of a system becomes much more difficult if the interacting parts *aren't* constant over time. 
In complex adaptive systems, "natural laws" at the level of the system aren't fixed, they can change over time as the interacting parts change. 
For example, the rules that seem to govern the economy depend on the structure of the economy, and on the usual, average behaviour of people. 
If these things change, so sometimes do the rules.
Even worse, a seemingly small change in the underlying parts or interactions can occasionally lead to dramatically different system rules and behaviours. 
Minor interaction details can therefore matter a lot.

In any given study you can only look at a limited set of conditions and interactions. 
Therefore it is often very cumbersome to figure out what's going on in a complex adaptive system. 
It can become almost impossible to predict what will happen if conditions change. 
We can still learn and know things about complex systems, even if their parts are not all identical and constant. 
But it requires a lot of work, and our ability to make generalised statements and predictions is rather limited.

### Predictability problems

This last point is worth emphasising. The behaviour of complex systems usually cannot be predicted very far into the future, even in the unlikely case that all elements and their interactions are known. 
This is not just because elements and interactions may sometimes change. 
The problem also exists in many complex physical systems, in which the parts themselves do not change. 

When there are many strong interactions, every element can end up influencing many other elements, including itself. 
And because interactions take time and this time may vary, it may become impossible to predict the precise order in which interactions take place. 
This creates an uncertainty about the outcome of interactions, which can rapidly get worse with time.[^chaos] 
This is the main reason why we cannot predict the weather with good accuracy more than a few days ahead.

And it gets worse. We saw that emergent properties allow us to know about and interact with things without having to know all of the underlying details. 
But the inverse isn't true. 
Even if we would have full knowledge about *all* details of physics and chemistry (which currently isn't the case), this wouldn't necessarily help us to explain and predict what happens at a higher, emergent level of organisation. 

Let's take an example from a complex social system: What happens in, say, regional politics cannot really be reduced to physics and chemistry, or even to neuroscience.[^reductionism]
It depends mostly on interactions between, in this case, politicians and other groups in a society. 
It also depends on interactions with other systems (for instance, economies) and other levels of organisation (like
national and international politics and geopolitical power relations).

In my [previous article](https://sustainsubstance.org/beyond-optimists-and-pessimists.html),
I talked about various ways of seeing the world in relation to sustainability. 
The ecomodernist worldview tends to emphasise the potential for large-scale technological solutions to sustainability problems, based on existing institutions and economic growth.
Ecomodernists strongly believe in the power of science and engineering.
In contrast, the antimodernist or neo-romantic worldview tends to promote smaller-scale solutions with a bigger role for nature and local communities. Neo-romantics often have much less confidence in the explanatory abilities of science, and they tend to distrust large-scale application of industrial approaches.

Neo-romantics often point out the fact that we live in a world that is dominated by complex systems. 
This has consequences for how much we can rely on large-scale control and on stable economic growth. 
Especially industrial approaches require conditions that are more or less stable, uniform and predictable. As we have seen, predictability is inherently limited in a complex world.

### Promises of "simplexity"

In the 1980s and 1990s, there was a hope that complexity science would allow us to eventually predict and control many complex systems.
Researchers observed that complex behaviour can sometimes arise from very simple interaction rules. 
There are many examples of this in nature, such as the [foraging of ants](https://www.youtube.com/watch?v=vG-QZOTc5_Q) or the [flocking of starlings](https://animals.howstuffworks.com/birds/starling-murmurations.htm).

The expectation was that we would be able to uncover simple rules to explain the behaviour of many other complex systems, including human societies. 
Indeed, there has been much progress in our understanding. 
But the more we learn, the more it seems that the potential for prediction and generalisation is limited. 

The details of a specific system can matter a lot. 
Even if there are simple rules underlying its behaviour, we still have to *find* those rules for every different system. 
And if conditions change, the rules can change as well and our predictions may no longer work.
Yet we would overstate the problem if we conclude that the world is too complex for us to understand, or that control is utterly impossible. 

Much depends on what our goals and expectations are.
The "industrial approach" to solving problems usually depends on maximising predictability and control.
As we have seen, this doesn't work well in systems that are more complex.
The many interactions that occur in a complex system put hard limits on predictability.
Often the response has been to simplify complex systems. 
Removing parts and interactions and reducing diversity makes a system more predictable, and easier to control and optimise.
This is for instance the approach that industrial agriculture has taken.

The problem is that in complex *adaptive* systems, the parts have usually adapted *to each other*.
If you remove parts and interactions, many such adaptations cease to function well, and problems begin to occur.
We often see this happen if we reduce the diversity of a natural system, or of a semi-natural system such as agriculture. An example of this is the occurrence of pests in agriculture. Pests are generally made worse by removal of natural predators or competitors that help keep down their numbers. Another example is the rapid decline of pollinating insects. Both problems are partially caused by decrease of diversity through pesticide use and the "optimisation" of agricultural landscapes for maximum yield. 

### Health despite uncertainty

An additional problem is that complex systems are hard to study, as we've already seen.
The scientific method relies to a large extent on reductionism.
If we cannot take a system apart and study its parts under controlled conditions, it becomes hard to understand how things work and what exactly is going on.
A good example of this is human health.
After more than a century of intense collective research effort, we know quite a lot about the various parts of the human body.
Yet we still don't fully understand how some of its most basic control mechanisms operate.

The complexity involved in something like the immune system or the body's energy regulation is enormous.
Every part seems connected to everything else, and it is often very hard to distinguish cause from effect.
We are able to replace some mechanical parts when they are broken, which in itself is very impressive.[^chemicalparts]
But when it comes to the major regulatory mechanisms that maintain our health, we are mostly unable to "fix" problems when they occur.
We simply do not understand the body well enough, and the exact cause of many problems still remains elusive.
It is at least clear that our body is very unlike a machine. We cannot simply shut it down, locate and replace the broken part and start it back up again.

However, this does not mean that we cannot improve our health or reduce the effects of disease.
We may not be able to fully control or understand the human body, but we are often quite capable of nudging it towards a more healthy state. 
And even if we can't, we can at least slow down damage and reduce its effects.
Even better, we can reduce the risks of disease occurring in the first place.

The above does not just apply to the human body, but to many other complex systems as well.
We may not be able to fully control or fix them, but we can try to understand them *better* while keeping in mind that we do not know all relevant details.
Partial understanding may already allow us to prevent problems.
And when problems do occur, we can often steer a system towards a healthier state, step by step through careful observation and management.

We certainly shouldn't ignore complexity, but we also shouldn't be overly afraid of it. 
The living world has always been complex, and in recent years we have learned a lot about the ways in which living systems don't just deal with complexity and unpredictability, but in some ways even use it to their advantage.


<div style="text-align: center; margin-left: auto; margin-right: auto;">
<img src="{static}/images/small-tangle.jpg" style="width: 25%; height: auto; border: 0px;"/>
</div>


*Images by Io Cooman.*

Do you want to be notified when future articles in this series are published? Subscribe to my [Substack](https://lvzon.substack.com/), or follow me on [Facebook](https://www.facebook.com/sustainsubstance), [Instagram](https://www.instagram.com/sustainsubstance), [Bluesky](https://bsky.app/profile/lvzon.bsky.social) or [Twitter/X](https://twitter.com/levienvanzon). You can also subscribe to our [Atom-feed](/feeds/all.atom.xml).



### Further reading

Strevens, Michael. *The Knowledge Machine: How Irrationality Created Modern Science*. W.W. Norton, 2020.     
<https://www.strevens.org/scientia>     
Philosopher Michael Strevens makes the argument that science is special 
mostly due to what he calls its "iron rule": Empirical observations
always have precedence over theoretical or philosophical explanations. 
Moreover, as an institution, science sets strict rules on acceptable behaviour 
and the things that may or may not be discussed in its official communication channels. 
This creates a buffer between public scientific work (which is published in journals)
and private beliefs (which may be discussed and published elsewhere). 
This explains why for instance Isaac Newton could both be one of the great
empirical scientists, and at the same time a highly religious alchemist, who believed in mystical forces.
Some of this is also discussed in the Jim Rutt Show podcast, [episode 106](https://www.jimruttshow.com/michael-strevens/),
and in Strevens' [paper](https://www.strevens.org/scientia/inextremis.shtml) *Science Is Irrational—and a Good Thing, Too*.

Waldrop, Mitchell M. *Complexity: The Emerging Science at the Edge of Order and Chaos*. Simon and Schuster, 1993.     
<https://www.simonandschuster.com/books/Complexity/Mitchell-M-Waldrop/9780671872342>     
This book by Mitchell Waldrop is what got me (and many others)
interested in complexity science. Since its publication, it has been
criticised for its narrow focus on the [Santa Fe Institute](https://www.santafe.edu/) and
its portrayal of complexity researchers as young
rebels fighting against a conservative scientific establishment clinging
on to reductionism (which makes for a good story but is not entirely accurate). 
Also, the book is now three decades old, and some of its
hopes for complexity science seem a little optimistic with current-day knowledge.
Especially the life sciences have progressed a lot since the early 1990s in their understanding of complex living systems, as is described for instance by Philip Ball in his book [How Life Works](https://how-life-works.philipball.co.uk), which is listed below. 
Yet despite such critical notes, *Complexity* still provides an attractive and readable introduction to many aspects of complex adaptive systems.

Holland, John H. *Complexity: A Very Short Introduction*. Oxford
University Press, 2014.     
<https://doi.org/10.1093/actrade/9780199662548.001.0001>     
A useful if somewhat technical introduction by John Holland, one of the founders of complexity science. Holland makes the distinction between complex physical systems (CPS) and complex adaptive systems (CAS). This to me was a revelation because it makes it much easier to see the limitations of "particle based" analyses and descriptions that were adapted from physics. These often apply quite well to CPS (or approximations thereof), but are often not a good description of CAS because they cannot deal well with adaptation and diversity.

Ball, Philip. *Why Society is a Complex Matter: Meeting Twenty-first Century Challenges with a New Kind of Science*. Springer Berlin Heidelberg, 2012.     
<https://link.springer.com/book/10.1007/978-3-642-29000-8>     
In the introduction chapter of this book, science writer Philip Ball offers a good introduction to complexity and its relevance to social systems. The rest of the book discusses examples of (moderately) complex social phenomena that have so far been studied relatively well: the behaviour of traffic and crowds, effects of contagion in how social norms get established, the spread of crime and disease, problems of social cooperation and the dynamics of social networks, financial systems, cities and military conflicts. The book ends with an overview of the ambitious 2013 [FuturICT](https://coss.ethz.ch/research/pastprojects/futurict.html) project, which promised better management of complex social problems through application of big data and complexity science, and which was followed up in 2017 by [FuturICT 2.0](https://coss.ethz.ch/research/pastprojects/FuturICT20.html). Interestingly, the official websites of both projects no longer exist. While ambitious tech-driven projects like these are certainly interesting, one does start to wonder about their ability to offer a significant and robust contribution to future solutions. There may have been valuable results, but it's hard to say. Clearly, the way in which such projects are funded for a limited period already makes it hard to maintain a long-term website describing project outcomes.

Gershenson, Carlos (2013) 'Facing Complexity: Prediction vs.
Adaptation', in À. Massip-Bonet and A. Bastardas-Boada (eds.)
*Complexity Perspectives on Language, Communication and Society*.
Berlin, Heidelberg: Springer (Understanding Complex Systems), pp.
3--14.     
<https://doi.org/10.1007/978-3-642-32817-6\_2>
(or [read PDF here](https://www.researchgate.net/profile/Carlos-Gershenson/publication/285965809_Facing_complexity_Prediction_vs_adaptation/links/591107baa6fdccbfd5a781fd/Facing-complexity-Prediction-vs-adaptation.pdf))     
Gershenson, Carlos (2013) 'The Implications of Interactions for Science and Philosophy', *Foundations of Science*, 18(4), pp. 781--790.     
<https://doi.org/10.1007/s10699-012-9305-8>
(or [read PDF here](https://www.academia.edu/download/31338551/ImplicationsInteractions-FoS.pdf))     
The work of [Carlos Gershenson](https://bingweb.binghamton.edu/~cgershensong/) offers several important insights on how the interactions in complex systems limit their predictability, and how we can deal with this. The two articles above give an accessible overview of these issues. Gershenson discusses problems with reductionism in cases where relevant nonlinear interactions add emergent information to the system that cannot be derived from just knowing the parts. This often leads to *computational irreducibility*: the only way to determine the future state of a system is to run it. Due to their inherent unpredictability, the perfect control of complex, open systems is utopic. Therefore systems should be made to be robust and adaptive. Engineered systems usually are neither.

Scott, James C. *Seeing Like a State: How Certain Schemes to Improve the Human Condition Have Failed*. New Haven: Yale University Press, 1998.     
<https://yalebooks.yale.edu/book/9780300246759/seeing-like-a-state/>     
In this insightful work, political scientist and anthropologist James C. Scott examines the history of [*High Modernism*](https://en.wikipedia.org/wiki/High_modernism), a worldview that reached its peak in the 1950s and 1960s and in which nature and tradition were considered messy, outdated and inefficient. Instead, the social and natural world should be reordered according to "rational" modern principles of science, technology, geometry and centralised planning. Scott shows how "scientific" foresters of the 19th century and the modernist states of the 20th century simplified the social and natural systems they presided over. In doing so, they destroyed much of the complex ecological and social fabric required for systems to function well.     
One of the final chapters is on agriculture. Scott shows that "all agriculture is local", while the results from agricultural research are always necessarily generalised, because no research method can take into account the near infinite number of possible local variations. The experience and skill of farmers is therefore required to translate and adapt generic results and instructions to actual local conditions. In effect, the farmer himself needs to be a researcher and experimenter as well. This is a far cry from the idea that agriculture can be practised by unskilled industrial workers applying an "optimal" one-size-fits-all recipe developed by experts.

Mukherjee, Siddhartha. *[The Laws of Medicine](https://www.ted.com/read/ted-books/ted-books-library/the-laws-of-medicine): Field Notes from an Uncertain Science*. Simon and Schuster, 2015.     
In this [short book](https://www.ted.com/read/ted-books/ted-books-library/the-laws-of-medicine), medical researcher, doctor and science writer [Siddhartha Mukherjee](https://siddharthamukherjee.com) argues that the practice of medial science differs from the way we usually think about science. We are used to thinking of science as providing certainty, often in the form of scientific laws. However, medical science and the practice of medicine mostly have to deal with *uncertainty*, because there is so much about the human body that we *don't* yet know. However we cannot give up in the face of such fundamental ignorance, because doctors still have to treat patients and keep them alive. Rather than "hard" scientific laws, Mukherjee argues that medicine has effective methods for dealing with uncertainty, imprecision, and incompleteness. And much of this depends on the skill and experience of medical practitioners, precisely because text book knowledge is incomplete and each patient is different.

Ball, Philip. *How Life Works: A User's Guide to the New Biology*. University of Chicago Press, 2023.      
<https://how-life-works.philipball.co.uk>     
To understand things we don't know, we necessarily think of them in terms that we *are* familiar with. One of the underlying themes of this fascinating book on how life works, is that we tend to think of living systems using metaphors from technology. Thus we think of cells as factories and we think of proteins as machines. We think of genes as computer software and we think of the brain as a computer. 
However, living systems mostly function *very* differently from human-built machines. The problem is that we tend to forget that we are using metaphors, and that they then start to limit our thinking in serious ways. And while science has a method for testing theories, it has no good method for uprooting inappropriate metaphors. 
Ball proposes that the metaphors we use for understanding living systems should mostly come from living systems. 
This is also discussed in the [Big Biology podcast, episode 119](https://www.bigbiology.org/episodes/2024/4/4/ep-119-biology-as-its-own-metaphor-with-phil-ball).


-----------

#### Footnotes

[^taylorism]: *In the 20th century, the efficiency of factories was maximised according to the "rational" principles of "scientific management" devised by Frederick Taylor and others.*     
The ideas of Taylor and his followers are still known as *Taylorism*, and were influential far beyond their original context of factory organisation. Many politicians, policy makers and designers saw scientific management as the key to designing a more rational and efficient society. The essay [*Between Taylorism and Technocracy*](https://doi.org/10.1177/002200947000500202) by Charles S. Maier (1970) discusses some of the main influences of Taylorism on European policies, politics and ideas in the decades leading up to the Second World War. Unfortunately this article is behind a paywall, if you do not have academic access you can read parts of it on [Google Books](https://books.google.nl/books?id=pmtFnrYHFOgC&lpg=PA211&ots=OUbqonk2zQ&lr&pg=PA211#v=onepage&f=false). For a more complete overview, see the [book](https://books.google.com/books?id=BFzpCgAAQBAJ&lpg=PR5&ots=MHNyDci-Wa&lr&pg=PP1#v=onepage) *Scientism and Technocracy in the Twentieth Century: The Legacy of Scientific Management*, by Richard G. Olson (2016).

[^bayesianbrain]: *To find out how accurate our explanations and predictions are, our brains constantly compare our expectations with our actual observations and experiences.*     
In its most concrete form, this is known as [Bayesian Brain](https://en.wikipedia.org/wiki/Bayesian_approaches_to_brain_function) Theory. A very readable account of the underlying ideas and their consequences is given by neuroscientist Anil Seth in his book [Being You: A New Science of Consciousness](https://www.anilseth.com/being-you/).

[^emergence]: Those familiar with [emergence](https://en.wikipedia.org/wiki/Emergence) may note that I use quite a broad definition of the concept here, which is certainly not universally used or accepted. While the idea may be very useful, emergence can also be a tricky and slippery concept once you try to get into the details---something which I shall not do here.

[^epa]: *As long as the interacting parts (say, molecules) and their surroundings are constant over time, their collective behaviour is often well-defined.*     
Why the derivation of macroscopic descriptions and laws from the microscopic behaviour of dynamically interacting parts is possible, is described in [Strevens (2005)](https://www.strevens.org/chaos/chaos_paper.shtml). It works by using probability theory to derive average group outcomes from individual behaviour plus interactions. It is actually quite surprising that this works as well as it does. This approach mostly works well in cases where there are *many* identical parts, and strong interactions are relatively rare. It has even been applied to *adaptive* systems, for instance in population ecology and genetics. This does however require us to treat adaptive systems as if they are physical systems: the parts are assumed to be mostly identical and not to change much over time.

[^chaos]: *Because interactions take time and this time may vary, it becomes impossible to predict the precise order in which interactions take place. This creates an uncertainty about the outcome of interactions, which can rapidly get worse with time.*     
Such unpredictability is often referred to as *chaos*, but chaos is a subtly different phenomenon that does not strictly require complexity. See [Gershenson & Heylighen (2004)](https://doi.org/10.48550/arXiv.nlin/0402023) and [Gershenson (2013)](https://doi.org/10.48550/arXiv.1105.2827) for a somewhat more detailed description of the distinction between deterministic chaos (i.e. sensitive dependence on initial conditions due to positive feedback) and the effect of variable time delays in complex interaction networks. Such complex networks have many possible interaction paths that may result in amplifying or attenuating feedback. If interaction times are not roughly constant, it is impossible to know beforehand which paths get activated in which order, and thus what the net outcome of interactions will be. Of course deterministic chaos and random noise may further compound the difficulties in predicting the behaviour of complex systems. However if there are large numbers of *similar* parts, strong interactions are relatively rare and the behaviour of parts is fairly consistent, variations tend to average out and system behaviour becomes much more predictable, as described in [Strevens (2005)](https://www.strevens.org/chaos/chaos_paper.shtml).

[^reductionism]: *What happens in, say, regional politics cannot really be reduced to physics and chemistry, or even to neuroscience.*     
It is a long-standing [discussion](https://en.wikipedia.org/wiki/Reductionism) whether this is possible *in principle*. But even if it would be, it wouldn't be possible in practice, so such discussions need not concern us here. There is however evidence that implementing aspects of human decision making into computer simulations can reproduce some collective social phenomena, including perhaps some voting behaviour. See for instance the work of [Joshua M. Epstein](https://www.jimruttshow.com/joshua-epstein/). While such simulations may contribute to our mechanistic understanding of system dynamics, they have little predictive power under real-world conditions, which are much too complex to simulate.

[^chemicalparts]: *We are able to replace some mechanical parts when they are broken, which in itself is very impressive.*     
We are even able to replace some body parts involved in chemical or electrical control or perception. Usually however these are not full replacements: they offer a simplified version of the original biological functions. Think of pacemakers, insulin pumps, bionic eyes and robotic prosthetic limbs and hands.

